{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/2019/01/20/weekend-hack-another-scraper/","result":{"data":{"site":{"siteMetadata":{"title":"Marcus Sanatan"}},"markdownRemark":{"id":"7be52532-b827-5591-a091-704ff74d2abb","excerpt":"So I recently started to write programming articles for another website. I thought it’d be a good idea to link the articles in my website. I’ve set it up here…","html":"<p>So I recently started to write programming articles for another website. I thought it’d be a good idea to link the articles in my website. I’ve set it up here: <a href=\"https://msanatan.com/categories/other/\">https://msanatan.com/categories/other/</a>.</p>\n<p>The first thing I needed to do was get all my articles in one go. The scraper consists 3 parts:</p>\n<ul>\n<li>Parse the HTML to get the articles from my user page - <a href=\"https://stackabuse.com/author/marcus\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><a href=\"https://stackabuse.com/author/marcus\">https://stackabuse.com/author/marcus</a></a></li>\n<li>Save each article as Markdown files with a <code class=\"language-text\">link</code> property</li>\n<li>Allow users to specify which author to scrape via command line arguments</li>\n</ul>\n<h2>Parsing</h2>\n<p>For parsing I used <a href=\"https://www.crummy.com/software/BeautifulSoup\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Beautiful Soup</a>, definitely one of the most popular scarping libraries for Python. I skipped on <code class=\"language-text\">lxml</code> as the page is very simple, there was no need for fancy XPath. This function returns all the posts in a list of dictionaries. I’m not copying the content, so all I need are the names, links and dates.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">parse_posts</span><span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">'''Recursively retrieves all the posts of an blog write in stack abuse'''</span>\n    logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">'Scraping {}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    posts <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\"># It's always good to set user-agent, makes the request looks more like a</span>\n    <span class=\"token comment\"># regualr browsing request, without it some sites would outright block you</span>\n    headers <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'User-Agent'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'</span><span class=\"token punctuation\">}</span>\n    response <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">,</span> headers<span class=\"token operator\">=</span>headers<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># Don't be too hasty, check that your response was actually succesful</span>\n    <span class=\"token keyword\">if</span> response <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span> <span class=\"token keyword\">and</span> response<span class=\"token punctuation\">.</span>status_code <span class=\"token operator\">==</span> <span class=\"token number\">200</span><span class=\"token punctuation\">:</span>\n        html <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">.</span>content<span class=\"token punctuation\">,</span> <span class=\"token string\">'html.parser'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Loop through all the articles</span>\n        <span class=\"token keyword\">for</span> article <span class=\"token keyword\">in</span> html<span class=\"token punctuation\">.</span>find_all<span class=\"token punctuation\">(</span><span class=\"token string\">'article'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            title_tag <span class=\"token operator\">=</span> article<span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span><span class=\"token string\">'h2'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'class'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'post-title'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">)</span>\n            title <span class=\"token operator\">=</span> title_tag<span class=\"token punctuation\">.</span>text\n            link <span class=\"token operator\">=</span> BASE_URL <span class=\"token operator\">+</span> title_tag<span class=\"token punctuation\">[</span><span class=\"token string\">'href'</span><span class=\"token punctuation\">]</span>\n            meta <span class=\"token operator\">=</span> article<span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span><span class=\"token string\">'div'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'class'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'post-meta'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\"># The date comes like December 10, 2018</span>\n            <span class=\"token comment\">#  We really want it like 2018-12-10</span>\n            date_text <span class=\"token operator\">=</span> meta<span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span><span class=\"token string\">'span'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'class'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'date'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text\n            date <span class=\"token operator\">=</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>strptime<span class=\"token punctuation\">(</span>date_text<span class=\"token punctuation\">,</span> <span class=\"token string\">'%B %d, %Y'</span><span class=\"token punctuation\">)</span>\n            post <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token string\">'title'</span><span class=\"token punctuation\">:</span> title<span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'link'</span><span class=\"token punctuation\">:</span> link<span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'date'</span><span class=\"token punctuation\">:</span> datetime<span class=\"token punctuation\">.</span>date<span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span>date<span class=\"token punctuation\">,</span> <span class=\"token string\">\"%Y-%m-%d\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">}</span>\n            posts<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>post<span class=\"token punctuation\">)</span>\n        logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">'{} posts found on page'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>posts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\"># Stack Abuse paginates every 5 posts, this collects the older ones</span>\n        pagination <span class=\"token operator\">=</span> html<span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span><span class=\"token string\">'nav'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'class'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'pagination'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>find<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'class'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'older-posts'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> pagination <span class=\"token keyword\">is</span> <span class=\"token keyword\">not</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">'Retrieving older posts'</span><span class=\"token punctuation\">)</span>\n            <span class=\"token comment\"># Who said you don't use recursion?</span>\n            <span class=\"token keyword\">return</span> posts <span class=\"token operator\">+</span> parse_posts<span class=\"token punctuation\">(</span>BASE_URL <span class=\"token operator\">+</span> pagination<span class=\"token punctuation\">[</span><span class=\"token string\">'href'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> posts\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        logging<span class=\"token punctuation\">.</span>error<span class=\"token punctuation\">(</span><span class=\"token string\">'Could not get a response for the link'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></code></pre></div>\n<h2>Saving Data</h2>\n<p>I needed to convert the data to markdown so that Hexo can use it. I figured that allowing JSON and CSV formats as well, this scraper could be of more use to others. Doesn’t matter too much, Python makes saving in each file type dead simple:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">get_posts_json</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> author_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">'''Dumps JSON for stack abuse articles'''</span>\n    posts <span class=\"token operator\">=</span> parse_posts<span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span>\n    logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">'Retrieved {} posts'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>posts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> json_file<span class=\"token punctuation\">:</span>\n        json<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>posts<span class=\"token punctuation\">,</span> json_file<span class=\"token punctuation\">,</span> indent<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_posts_csv</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> author_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">'''Saves CSV file for stack abuse articles'''</span>\n    posts <span class=\"token operator\">=</span> parse_posts<span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span>\n    logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">'Retrieved {} posts'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>posts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    headers <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Title'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Link'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Date'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>filename<span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> csv_file<span class=\"token punctuation\">:</span>\n        csv_writer <span class=\"token operator\">=</span> csv<span class=\"token punctuation\">.</span>writer<span class=\"token punctuation\">(</span>csv_file<span class=\"token punctuation\">,</span> delimiter<span class=\"token operator\">=</span><span class=\"token string\">','</span><span class=\"token punctuation\">,</span> quoting<span class=\"token operator\">=</span>csv<span class=\"token punctuation\">.</span>QUOTE_ALL<span class=\"token punctuation\">)</span>\n        csv_writer<span class=\"token punctuation\">.</span>writerow<span class=\"token punctuation\">(</span>headers<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> post <span class=\"token keyword\">in</span> posts<span class=\"token punctuation\">:</span>\n            csv_writer<span class=\"token punctuation\">.</span>writerow<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>post<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> post<span class=\"token punctuation\">[</span><span class=\"token string\">'link'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> post<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_posts_markdown</span><span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">'''Saves posts as markdown files to work in Hexo'''</span>\n    posts <span class=\"token operator\">=</span> parse_posts<span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span>\n    logging<span class=\"token punctuation\">.</span>info<span class=\"token punctuation\">(</span><span class=\"token string\">'Retrieved {} posts'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>posts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># As markdown produces many files, it's neater to have them in one folder</span>\n    pathlib<span class=\"token punctuation\">.</span>Path<span class=\"token punctuation\">(</span><span class=\"token string\">'articles'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>mkdir<span class=\"token punctuation\">(</span>exist_ok<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> post <span class=\"token keyword\">in</span> posts<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># Use the slug as it's a more appropriate file name</span>\n        post_slug <span class=\"token operator\">=</span> slugify<span class=\"token punctuation\">(</span>post<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'articles/{}.md'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>post_slug<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n            f<span class=\"token punctuation\">.</span>writelines<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n                <span class=\"token string\">'---\\n'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'title: {}\\n'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>post<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'date: {}\\n'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>post<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'categories: [other]\\n'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'link: {}\\n'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>post<span class=\"token punctuation\">[</span><span class=\"token string\">'link'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'---\\n'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Command Line Arguments</h2>\n<p>Software is used by humans, always make your programs friendly. Python comes with a flexible argument parsing library which brings some order and useful information. Even for small programs like this, it feels better than processing <code class=\"language-text\">sys.argv</code> values myself. We put the <code class=\"language-text\">argparse</code> logic in the <code class=\"language-text\">main</code> function:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">'''Argument parser for scraper'''</span>\n    <span class=\"token comment\"># I imported the library like: from argparse import ArgumentParser</span>\n    <span class=\"token comment\"># For most cases you just need the ArgumentParser class</span>\n    parser <span class=\"token operator\">=</span> ArgumentParser<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">'Web scraper for Stack Abuse writers'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># Adding an argument is pretty simple, I give the short and long forms,</span>\n    <span class=\"token comment\"># specify the property the value will be saves as in dest and write a</span>\n    <span class=\"token comment\"># useful help message. In this case the author should be required</span>\n    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-a'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'--author'</span><span class=\"token punctuation\">,</span> dest<span class=\"token operator\">=</span><span class=\"token string\">'author'</span><span class=\"token punctuation\">,</span>\n                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'Writer whose articles you want'</span><span class=\"token punctuation\">,</span> required<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># The user selects what format they would like the data in. A file can't be</span>\n    <span class=\"token comment\"># JSON and CSV or CSV and Markdown at the same time so we make these options</span>\n    <span class=\"token comment\"># mutually exclusive.</span>\n    group <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>add_mutually_exclusive_group<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    group<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--csv'</span><span class=\"token punctuation\">,</span> action<span class=\"token operator\">=</span><span class=\"token string\">'store_true'</span><span class=\"token punctuation\">,</span>\n                       <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'Save data in CSV format'</span><span class=\"token punctuation\">)</span>\n    group<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--json'</span><span class=\"token punctuation\">,</span> action<span class=\"token operator\">=</span><span class=\"token string\">'store_true'</span><span class=\"token punctuation\">,</span>\n                       <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'Save data in JSON format'</span><span class=\"token punctuation\">)</span>\n    group<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'--markdown'</span><span class=\"token punctuation\">,</span> action<span class=\"token operator\">=</span><span class=\"token string\">'store_true'</span><span class=\"token punctuation\">,</span>\n                       <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'Save data as Markdown articles for Hexo'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># A simple way to manage log levels in your app!</span>\n    parser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">'-l'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'--loglevel'</span><span class=\"token punctuation\">,</span> dest<span class=\"token operator\">=</span><span class=\"token string\">'loglevel'</span><span class=\"token punctuation\">,</span>\n                        <span class=\"token builtin\">help</span><span class=\"token operator\">=</span><span class=\"token string\">'Select log level'</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token string\">'info'</span><span class=\"token punctuation\">)</span>\n    args <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>parse_args<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># Where all the magic happens</span>\n\n    <span class=\"token comment\"># Set logging preferences</span>\n    <span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>loglevel <span class=\"token operator\">==</span> <span class=\"token string\">'error'</span><span class=\"token punctuation\">:</span>\n        log_level <span class=\"token operator\">=</span> logging<span class=\"token punctuation\">.</span>ERROR\n    <span class=\"token keyword\">elif</span> args<span class=\"token punctuation\">.</span>loglevel <span class=\"token operator\">==</span> <span class=\"token string\">'debug'</span><span class=\"token punctuation\">:</span>\n        log_level <span class=\"token operator\">=</span> logging<span class=\"token punctuation\">.</span>DEBUG\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        log_level <span class=\"token operator\">=</span> logging<span class=\"token punctuation\">.</span>INFO\n\n    logging<span class=\"token punctuation\">.</span>basicConfig<span class=\"token punctuation\">(</span>filename<span class=\"token operator\">=</span><span class=\"token string\">'stackabuse_scraper.log'</span><span class=\"token punctuation\">,</span>level<span class=\"token operator\">=</span>log_level<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># BASE_URL was defined earlier in the script, fyi</span>\n    author_url <span class=\"token operator\">=</span> <span class=\"token string\">'{}/author/{}/'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>BASE_URL<span class=\"token punctuation\">,</span> args<span class=\"token punctuation\">.</span>author<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># Determine output format</span>\n    <span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>csv<span class=\"token punctuation\">:</span>\n        get_posts_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'stackabuse_articles.csv'</span><span class=\"token punctuation\">,</span> author_url<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">elif</span> args<span class=\"token punctuation\">.</span>json<span class=\"token punctuation\">:</span>\n        get_posts_json<span class=\"token punctuation\">(</span><span class=\"token string\">'stackabuse_articles.json'</span><span class=\"token punctuation\">,</span> author_url<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">elif</span> args<span class=\"token punctuation\">.</span>markdown<span class=\"token punctuation\">:</span>\n        get_posts_markdown<span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># Put a default case for that one user who'll try to break it :-/</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>json<span class=\"token punctuation\">.</span>dumps<span class=\"token punctuation\">(</span>parse_posts<span class=\"token punctuation\">(</span>author_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Conclusion</h2>\n<p>When I run <code class=\"language-text\">python3 stackabuse_scraper.py -a marcus --markdown</code> I get the following Markdown file as  output:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">---\ntitle: Building a GraphQL API with Django\ndate: 2018-12-10\ncategories: [other]\nlink: https://stackabuse.com/building-a-graphql-api-with-django/\n---</code></pre></div>\n<p>Exactly what I wanted and usable with Hexo! This was just some of the annotated code, you can find the full script at <a href=\"https://github.com/msanatan/stackabuse_scraper\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><a href=\"https://github.com/msanatan/stackabuse_scraper\">https://github.com/msanatan/stackabuse_scraper</a></a>. That’s all I got through to this weekend, till next time</p>\n<p>Happy Hacking!</p>","frontmatter":{"title":"Weekend Hack, Another Scraper","tags":["python","beautiful soup"],"date":"2019-01-20","updated":"2019-02-02"}},"previous":{"fields":{"slug":"/blog/2019/01/14/static-sites-for-quick-relief"},"frontmatter":{"title":"Static Sites for Quick Relief"}},"next":{"fields":{"slug":"/blog/2019/02/03/adding-posts-from-another-site-to-hexo"},"frontmatter":{"title":"Add Posts from Another Site to Hexo"}}},"pageContext":{"id":"7be52532-b827-5591-a091-704ff74d2abb","previousPostId":"24ea833c-81f0-5030-95ad-d1f5a33fdc75","nextPostId":"1076e2d7-5897-50d6-b6e1-0a2fef2f5d65"}},"staticQueryHashes":["1391858338"],"slicesMap":{}}